LLM - large language model
Neural network
Neural is small function
Neurals are connected
Each connection has a weight
Convolutional Neural Networks (CNN) - neurons are connected in a grid. Used for image recognition
Transformer Architecture - give the connections different weights

Training takes text input and tries to generate a model that makes useful text output

RLHF: reinforcement learning from human feedback

An LLM Predicts Which Word Should Follow the Previous

Words or parts of words are called tokens

The GPT-3 model that gpt-3.5-turbo model is based on has 175 billion weights, meaning that the 30 tokens of input text would result in 30 x 175 billion = 5.25 trillion calculations





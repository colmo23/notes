NLP - Natural Language Processing
sentiment analysis - good or bad
text classification: politics, sports, drama
part of speech tagging: verb, noun, etc

Text preprocessing: 

Tokenization: break down sentances to words

Lemmatization: reduce words into base forms or lemmas
   eg "am, is, are, was" are all lemmas of "be"

Stemming: removing word prefixes and suffixes
  eg happynss -> happi


models that can predict the next token based on the previous sequence of tokens (context) are
called language models

n-gram - sequence of n words or tokens

vec2word - vector representation of a word in a multidimensional
